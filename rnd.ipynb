{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62100261-a489-4683-b9cc-bef755b761f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe501f21-aa6f-4efa-97ef-20514d6768f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./dataset/names.txt', 'r') as f:\n",
    "    names = f.read().splitlines()\n",
    "import random\n",
    "random.seed(108)\n",
    "random.shuffle(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0deb490b-c410-45de-9397-d610b08458f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = ['.'] + sorted(set(''.join(names)))\n",
    "vocab_size = len(vocab)\n",
    "itos = dict(enumerate(vocab))\n",
    "stoi = dict((s, i) for i, s in itos.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8a7ca17-ced0-487e-b457-362b09632d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 3\n",
    "embed_size = 2\n",
    "l1 = batch * embed_size\n",
    "l2 = 100\n",
    "l3 = vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20918df9-919d-40bd-82ec-9537d77c545c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = [], []\n",
    "\n",
    "for name in names:\n",
    "    content = [0] * batch \n",
    "    for ch in name + '.':\n",
    "        ch = stoi[ch]\n",
    "        X.append(list(content))\n",
    "        Y.append(ch)\n",
    "        content.append(ch)\n",
    "        content = content[1:]\n",
    "X = torch.tensor(X)\n",
    "Y = torch.tensor(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b13e3791-6f19-4b35-b69e-401d1cf7f054",
   "metadata": {},
   "outputs": [],
   "source": [
    "itr = int(0.8 * X.shape[0])\n",
    "idev = int(0.9 * X.shape[0])\n",
    "Xtr, Xdev, Xts = X.tensor_split((itr, idev))\n",
    "Ytr, Ydev, Yts = Y.tensor_split((itr, idev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "717139dd-d955-43aa-a17c-584017c7e494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parametes: 3481\n"
     ]
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(123)\n",
    "C = torch.randn((vocab_size, embed_size), requires_grad=True, generator=g)\n",
    "W1 = torch.randn((l1, l2), requires_grad=True, generator=g)\n",
    "b1 = torch.randn((l2,), requires_grad=True, generator=g)\n",
    "W2 = torch.randn((l2, l3), requires_grad=True, generator=g)\n",
    "b2 = torch.randn((l3,), requires_grad=True, generator=g)\n",
    "params = [C, W1, b1, W2, b2]\n",
    "print(f'Parametes: {sum([p.nelement() for p in params])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "870ee2d4-a6cd-4595-a865-e25a40a5301e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3987, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for e in range(10000):\n",
    "    b = torch.randint(0, Xtr.shape[0], (int(Xtr.shape[0]*0.01),))\n",
    "    h = torch.tanh(C[Xtr[b]].view(-1, l1) @ W1 + b1)\n",
    "    logits = h @ W2 + b2\n",
    "    nll = nn.functional.cross_entropy(logits, Ytr[b])\n",
    "    for p in params:\n",
    "        p.grad = None\n",
    "    nll.backward()\n",
    "    for p in params:\n",
    "        p.data -= 0.1 * p.grad\n",
    "print(nll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0f20b59-e88d-418e-b927-ada8662f82f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.4067)\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    h = torch.tanh(C[Xtr].view(-1, l1) @ W1 + b1)\n",
    "    logits = h @ W2 + b2\n",
    "    exp = logits.exp()\n",
    "    probs = exp/exp.sum(dim=1, keepdim=True)\n",
    "    nll = -probs[torch.arange(Xtr.shape[0]), Ytr].log().mean()\n",
    "    print(nll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e14c309-ec67-4f80-99f5-537612f275a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.4180)\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    h = torch.tanh(C[Xdev].view(-1, l1) @ W1 + b1)\n",
    "    logits = h @ W2 + b2\n",
    "    exp = logits.exp()\n",
    "    probs = exp/exp.sum(dim=1, keepdim=True)\n",
    "    nll = -probs[torch.arange(Xdev.shape[0]), Ydev].log().mean()\n",
    "    print(nll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ba47ca14-2ff6-4495-8e17-ef5710a079eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jaol\n"
     ]
    }
   ],
   "source": [
    "out = [0] * batch\n",
    "idx = out[-batch:]\n",
    "\n",
    "while True:\n",
    "    h = torch.tanh(C[idx].view(-1, l1) @ W1 + b1)\n",
    "    logits = h @ W2 + b2\n",
    "    exp = logits.exp()\n",
    "    probs = exp/exp.sum(dim=1, keepdim=True)\n",
    "    pred = torch.multinomial(probs, 1, replacement=True, generator=g).item()\n",
    "    idx.append(pred)\n",
    "    out.append(pred)\n",
    "    idx = idx[1:]\n",
    "    if pred == 0:\n",
    "        break\n",
    "print(''.join(itos[i] for i in out if i))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "syntel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
